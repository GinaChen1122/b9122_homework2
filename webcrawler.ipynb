{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with url=['https://www8.gsb.columbia.edu']\n"
     ]
    }
   ],
   "source": [
    "seed_url = \"https://www8.gsb.columbia.edu\"\n",
    "\n",
    "urls = [seed_url]    #queue of urls to crawl\n",
    "seen = [seed_url]    #stack of urls seen so far\n",
    "opened = []          #we keep track of seen urls so that we don't revisit them\n",
    "\n",
    "maxNumUrl = 50; #set the maximum number of urls to visit\n",
    "print(\"Starting with url=\" + str(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num. of URLs in stack: 0 \n",
      "Trying to access= https://www8.gsb.columbia.edu\n",
      "Unable to access= https://www8.gsb.columbia.edu\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1076)>\n"
     ]
    }
   ],
   "source": [
    "while len(urls) > 0 and len(opened) < maxNumUrl:\n",
    "    # DEQUEUE A URL FROM urls AND TRY TO OPEN AND READ IT\n",
    "    try:\n",
    "        curr_url = urls.pop(0)\n",
    "        print(\"num. of URLs in stack: %d \" % len(urls))\n",
    "        print(\"Trying to access= \" + curr_url)\n",
    "        req = urllib.request.Request(curr_url, headers = {'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urllib.request.urlopen(req).read()\n",
    "        opened.append(curr_url)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\"Unable to access= \" + curr_url)\n",
    "        print(ex)\n",
    "        continue    #skip code below\n",
    "\n",
    "    # IF URL OPENS, CHECK WHICH URLS THE PAGE CONTAINS\n",
    "    # ADD THE URLS FOUND TO THE QUEUE url AND seen\n",
    "    soup = BeautifulSoup(webpage)  #creates object soup\n",
    "    # Put child URLs into the stack\n",
    "    for tag in soup.find_all('a', href = True): #find tags with links\n",
    "        childUrl = tag['href'] #extract just the link\n",
    "        o_childurl = childUrl\n",
    "        childUrl = urllib.parse.urljoin(seed_url, childUrl)\n",
    "        print(\"seed_url=\" + seed_url)\n",
    "        print(\"original childurl=\" + o_childurl)\n",
    "        print(\"childurl=\" + childUrl)\n",
    "        print(\"seed_url in childUrl=\" + str(seed_url in childUrl))\n",
    "        print(\"Have we seen this childUrl=\" + str(childUrl in seen))\n",
    "        if seed_url in childUrl and childUrl not in seen:\n",
    "            print(\"***urls.append and seen.append***\")\n",
    "            urls.append(childUrl)\n",
    "            seen.append(childUrl)\n",
    "        else:\n",
    "            print(\"######\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num. of URLs seen = 1, and scanned = 0\n",
      "List of seen URLs:\n",
      "https://www8.gsb.columbia.edu\n"
     ]
    }
   ],
   "source": [
    "print(\"num. of URLs seen = %d, and scanned = %d\" % (len(seen), len(opened)))\n",
    "print(\"List of seen URLs:\")\n",
    "for seen_url in seen:\n",
    "    print(seen_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
